{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef49d667",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation\n",
    "* LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785faaaf",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544d53c",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f61c904",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c7799",
   "metadata": {},
   "source": [
    "## Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42d889d",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac01d67",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "file = 'netflix_small.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572e677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ea30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e260324",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    embedding=embeddings,\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba5ec6d",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f22dac",
   "metadata": {},
   "source": [
    "### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a505f9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='title: Vendetta: Truth, Lies and The Mafia\\ndescription: Sicily boasts a bold \"Anti-Mafia\" coalition. But what happens when those trying to bring down organized crime are accused of being criminals themselves?', metadata={'source': 'netflix_small.csv', 'row': 10})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6878736c",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: The Great British Baking Show\n",
      "description: A talented batch of amateur bakers face off in a 10-week competition, whipping up their best dishes in the hopes of being named the U.K.'s best.\n"
     ]
    }
   ],
   "source": [
    "print(data[8].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da6093",
   "metadata": {},
   "source": [
    "### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd839e9f",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What does Sicily boasts of?\",\n",
    "        \"answer\": \"Anti-Mafia coalition\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How long is the bakers face off?\",\n",
    "        \"answer\": \"10 week\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dadf96",
   "metadata": {},
   "source": [
    "### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d20562",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25ef800",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c7e392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QAGenerateChain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8bc6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_chain.apply_and_parse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15c8694f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\langchain\\chains\\llm.py:367: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6c8cc44",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qa_pairs': {'query': 'According to the document, what is the title of the film being described?',\n",
       "   'answer': 'The title of the film being described is \"Dick Johnson Is Dead.\"'}},\n",
       " {'qa_pairs': {'query': 'What is the title and description of the show \"Blood & Water\"?',\n",
       "   'answer': 'The title of the show is \"Blood & Water\" and the description is: \"After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.\"'}},\n",
       " {'qa_pairs': {'query': 'According to the document, why is skilled thief Mehdi and his team of robbers pulled into a violent and deadly turf war?',\n",
       "   'answer': 'Skilled thief Mehdi and his team of robbers are pulled into a violent and deadly turf war in order to protect his family from a powerful drug lord.'}},\n",
       " {'qa_pairs': {'query': 'What is the title of the reality series that takes place at the Orleans Justice Center in New Orleans?',\n",
       "   'answer': 'Jailbirds New Orleans.'}},\n",
       " {'qa_pairs': {'query': 'What is the title of the document and what is the description provided in the document?',\n",
       "   'answer': 'The title of the document is \"Kota Factory\" and the description states that in a city of coaching centers known to train India\\'s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.'}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43fa2972",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='title: Dick Johnson Is Dead\\ndescription: As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.', metadata={'source': 'netflix_small.csv', 'row': 0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0beec7",
   "metadata": {},
   "source": [
    "### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d276170",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb095bd7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sicily boasts a bold \"Anti-Mafia\" coalition.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466ffca",
   "metadata": {},
   "source": [
    "## Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "809effd6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c017ea7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What does Sicily boasts of?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What does Sicily boasts of?\",\n",
      "  \"context\": \"title: Vendetta: Truth, Lies and The Mafia\\ndescription: Sicily boasts a bold \\\"Anti-Mafia\\\" coalition. But what happens when those trying to bring down organized crime are accused of being criminals themselves?<<<<>>>>>title: Europe's Most Dangerous Man: Otto Skorzeny in Spain\\ndescription: Declassified documents reveal the post-WWII life of Otto Skorzeny, a close Hitler ally who escaped to Spain and became an adviser to world presidents.<<<<>>>>>title: Jailbirds New Orleans\\ndescription: Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.<<<<>>>>>title: Jaguar\\ndescription: In the 1960s, a Holocaust survivor joins a group of self-trained spies who seek justice against Nazis fleeing to Spain to hide after WWII.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\ntitle: Vendetta: Truth, Lies and The Mafia\\ndescription: Sicily boasts a bold \\\"Anti-Mafia\\\" coalition. But what happens when those trying to bring down organized crime are accused of being criminals themselves?<<<<>>>>>title: Europe's Most Dangerous Man: Otto Skorzeny in Spain\\ndescription: Declassified documents reveal the post-WWII life of Otto Skorzeny, a close Hitler ally who escaped to Spain and became an adviser to world presidents.<<<<>>>>>title: Jailbirds New Orleans\\ndescription: Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.<<<<>>>>>title: Jaguar\\ndescription: In the 1960s, a Holocaust survivor joins a group of self-trained spies who seek justice against Nazis fleeing to Spain to hide after WWII.\\nHuman: What does Sicily boasts of?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [1.10s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Sicily boasts a bold \\\"Anti-Mafia\\\" coalition.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Sicily boasts a bold \\\"Anti-Mafia\\\" coalition.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 13,\n",
      "                \"prompt_tokens\": 237,\n",
      "                \"total_tokens\": 250\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bc27364f-84e1-481a-9931-f5b385033f5b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 13,\n",
      "      \"prompt_tokens\": 237,\n",
      "      \"total_tokens\": 250\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.10s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Sicily boasts a bold \\\"Anti-Mafia\\\" coalition.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.10s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Sicily boasts a bold \\\"Anti-Mafia\\\" coalition.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [1.53s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"Sicily boasts a bold \\\"Anti-Mafia\\\" coalition.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sicily boasts a bold \"Anti-Mafia\" coalition.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bc68e8f",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a640e54f",
   "metadata": {},
   "source": [
    "## LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb2c558e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'According to the document, what is the title of the film being described?',\n",
       " 'answer': 'The title of the film being described is \"Dick Johnson Is Dead.\"'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[2]['qa_pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35c925c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [i['qa_pairs'] if 'qa_pairs' in i.keys() else i for i in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ab741be",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad617df2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2dd0e98",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed6b73cd",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0412c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': 'CORRECT'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99ce6c8c",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What does Sicily boasts of?\n",
      "Real Answer: Anti-Mafia coalition\n",
      "Predicted Answer: Sicily boasts a bold \"Anti-Mafia\" coalition.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: How long is the bakers face off?\n",
      "Real Answer: 10 week\n",
      "Predicted Answer: The bakers face off in a 10-week competition on \"The Great British Baking Show.\"\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: According to the document, what is the title of the film being described?\n",
      "Real Answer: The title of the film being described is \"Dick Johnson Is Dead.\"\n",
      "Predicted Answer: The title of the film being described is \"Intrusion.\"\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the title and description of the show \"Blood & Water\"?\n",
      "Real Answer: The title of the show is \"Blood & Water\" and the description is: \"After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.\"\n",
      "Predicted Answer: The title is \"Blood & Water\" and the description is: After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: According to the document, why is skilled thief Mehdi and his team of robbers pulled into a violent and deadly turf war?\n",
      "Real Answer: Skilled thief Mehdi and his team of robbers are pulled into a violent and deadly turf war in order to protect his family from a powerful drug lord.\n",
      "Predicted Answer: Skilled thief Mehdi and his team of robbers are pulled into a violent and deadly turf war to protect his family from a powerful drug lord.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 5:\n",
      "Question: What is the title of the reality series that takes place at the Orleans Justice Center in New Orleans?\n",
      "Real Answer: Jailbirds New Orleans.\n",
      "Predicted Answer: The title of the reality series that takes place at the Orleans Justice Center in New Orleans is \"Jailbirds New Orleans.\"\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 6:\n",
      "Question: What is the title of the document and what is the description provided in the document?\n",
      "Real Answer: The title of the document is \"Kota Factory\" and the description states that in a city of coaching centers known to train India's finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.\n",
      "Predicted Answer: I don't know.\n",
      "Predicted Grade: INCORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['results'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e1095",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "graded_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a770f",
   "metadata": {},
   "source": [
    "## LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f251c",
   "metadata": {},
   "source": [
    "The LangChain evaluation platform, LangChain Plus, can be accessed here https://www.langchain.plus/.  \n",
    "Use the invite code `lang_learners_2023`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52536488",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe709dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0717939",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fe6ef",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310496b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ce92f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d868e8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85705ffc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7d308",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20b78e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
